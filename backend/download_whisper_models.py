#!/usr/bin/env python3
"""
Whisperæ¨¡å‹ä¸‹è½½è„šæœ¬
ä¸‹è½½baseå’Œturboæ¨¡å‹åˆ°modelsæ–‡ä»¶å¤¹
"""

import os
import sys
import shutil
import whisper
from pathlib import Path
import torch

def download_models():
    """ä¸‹è½½Whisperæ¨¡å‹åˆ°modelsæ–‡ä»¶å¤¹"""
    
    # ç¡®ä¿modelsæ–‡ä»¶å¤¹å­˜åœ¨
    models_dir = Path("models")
    models_dir.mkdir(exist_ok=True)
    
    print("ğŸš€ å¼€å§‹ä¸‹è½½Whisperæ¨¡å‹...")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜ç›®å½•: {models_dir.absolute()}")
    
    # è¦ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨
    models_to_download = ["base", "turbo"]
    
    for model_name in models_to_download:
        try:
            print(f"\nğŸ“¥ æ­£åœ¨ä¸‹è½½ {model_name} æ¨¡å‹...")
            
            # ä¸‹è½½æ¨¡å‹åˆ°é»˜è®¤ä½ç½®
            model = whisper.load_model(model_name)
            
            # è·å–æ¨¡å‹æ–‡ä»¶çš„å®é™…è·¯å¾„
            model_filename = f"{model_name}.pt" if model_name != "turbo" else "large-v3-turbo.pt"
            
            # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
            import whisper
            cache_dir = os.path.expanduser("~/.cache/whisper")
            
            # å°è¯•ä¸åŒçš„å¯èƒ½è·¯å¾„
            possible_paths = [
                os.path.join(cache_dir, model_filename),
                os.path.join(os.path.dirname(whisper.__file__), "assets", model_filename),
            ]
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç»åœ¨å½“å‰ç›®å½•
            local_path = models_dir / model_filename
            
            # å¦‚æœæ¨¡å‹å·²ç»å­˜åœ¨ï¼Œè·³è¿‡
            if local_path.exists():
                size_mb = local_path.stat().st_size / (1024 * 1024)
                print(f"âœ… {model_name} æ¨¡å‹å·²å­˜åœ¨ ({size_mb:.1f} MB)")
                continue
            
            # ä¿å­˜æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
            torch.save(model.state_dict(), local_path)
            
            if local_path.exists():
                size_mb = local_path.stat().st_size / (1024 * 1024)
                print(f"âœ… {model_name} æ¨¡å‹ä¸‹è½½å®Œæˆï¼({size_mb:.1f} MB)")
            else:
                print(f"âŒ {model_name} æ¨¡å‹ä¿å­˜å¤±è´¥")
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½ {model_name} æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            continue
    
    # æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶
    print(f"\nğŸ“‹ æ£€æŸ¥modelsæ–‡ä»¶å¤¹å†…å®¹:")
    if models_dir.exists():
        total_size = 0
        for file in models_dir.iterdir():
            if file.is_file():
                size_mb = file.stat().st_size / (1024 * 1024)
                total_size += size_mb
                print(f"   - {file.name} ({size_mb:.1f} MB)")
        
        if total_size > 0:
            print(f"\nğŸ“Š æ€»å¤§å°: {total_size:.1f} MB")
        else:
            print("   (æ–‡ä»¶å¤¹ä¸ºç©º)")
    
    print("\nğŸ‰ æ¨¡å‹ä¸‹è½½å®Œæˆï¼")

def test_models():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åŠ è½½...")
    
    models_dir = Path("models")
    
    for model_file in models_dir.glob("*.pt"):
        try:
            print(f"ğŸ“ æµ‹è¯•åŠ è½½: {model_file.name}")
            
            # æ ¹æ®æ–‡ä»¶åç¡®å®šæ¨¡å‹åç§°
            if "turbo" in model_file.name:
                model_name = "turbo"
            else:
                model_name = model_file.stem
            
            # å°è¯•åŠ è½½æ¨¡å‹
            model = whisper.load_model(model_name)
            print(f"âœ… {model_name} æ¨¡å‹åŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ {model_file.name} å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    download_models()
    test_models()